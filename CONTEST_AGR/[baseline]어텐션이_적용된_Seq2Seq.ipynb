{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "[baseline]어텐션이_적용된 Seq2Seq.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPAKTTM_vW7f"
      },
      "source": [
        "baseline.csv<br>\n",
        ".. ├ models<br>\n",
        ".. └ data<br>\n",
        ".... ├ public_data<br>\n",
        ".... │ .. ├ train_AT_TSALET_ALL<br>\n",
        ".... │ .. ├ test_AT_TSALET_ALL<br>\n",
        ".... │ .. ├ test_files<br>\n",
        ".... │ .. └ train.csv<br>\n",
        ".... ├ prviate_data<br>\n",
        ".... │ .. ├ AT_TSALET_ALL<br>\n",
        ".... │ .. ├ private_data<br>\n",
        ".... └ sample_submission.csv<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlDvRMk6vW7h"
      },
      "source": [
        "## 사용 패키지"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2j6xu6djzQjr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7bf3d08-5f8b-49c6-db92-1bbe58407be7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQRN8cHYvW7i"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import os\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0krNjCT9vW7j"
      },
      "source": [
        "## 재현을 위한 랜덤시드 고정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPmAhRHOvW7j"
      },
      "source": [
        "def seed_everything(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # type: ignore\n",
        "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
        "    torch.backends.cudnn.benchmark = True  # type: ignore"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMPpvtNhvW7k"
      },
      "source": [
        "seed_everything(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFflOzePvW7k"
      },
      "source": [
        "## 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMFhAN9HvW7l"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/Dacon_data/public_data/train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuoL5tMjvW7m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "ab92eecf-7b84-485c-ab50-e4374a469da1"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>요일</th>\n",
              "      <th>배추_거래량(kg)</th>\n",
              "      <th>배추_가격(원/kg)</th>\n",
              "      <th>무_거래량(kg)</th>\n",
              "      <th>무_가격(원/kg)</th>\n",
              "      <th>양파_거래량(kg)</th>\n",
              "      <th>양파_가격(원/kg)</th>\n",
              "      <th>건고추_거래량(kg)</th>\n",
              "      <th>건고추_가격(원/kg)</th>\n",
              "      <th>마늘_거래량(kg)</th>\n",
              "      <th>마늘_가격(원/kg)</th>\n",
              "      <th>대파_거래량(kg)</th>\n",
              "      <th>대파_가격(원/kg)</th>\n",
              "      <th>얼갈이배추_거래량(kg)</th>\n",
              "      <th>얼갈이배추_가격(원/kg)</th>\n",
              "      <th>양배추_거래량(kg)</th>\n",
              "      <th>양배추_가격(원/kg)</th>\n",
              "      <th>깻잎_거래량(kg)</th>\n",
              "      <th>깻잎_가격(원/kg)</th>\n",
              "      <th>시금치_거래량(kg)</th>\n",
              "      <th>시금치_가격(원/kg)</th>\n",
              "      <th>미나리_거래량(kg)</th>\n",
              "      <th>미나리_가격(원/kg)</th>\n",
              "      <th>당근_거래량(kg)</th>\n",
              "      <th>당근_가격(원/kg)</th>\n",
              "      <th>파프리카_거래량(kg)</th>\n",
              "      <th>파프리카_가격(원/kg)</th>\n",
              "      <th>새송이_거래량(kg)</th>\n",
              "      <th>새송이_가격(원/kg)</th>\n",
              "      <th>팽이버섯_거래량(kg)</th>\n",
              "      <th>팽이버섯_가격(원/kg)</th>\n",
              "      <th>토마토_거래량(kg)</th>\n",
              "      <th>토마토_가격(원/kg)</th>\n",
              "      <th>청상추_거래량(kg)</th>\n",
              "      <th>청상추_가격(원/kg)</th>\n",
              "      <th>백다다기_거래량(kg)</th>\n",
              "      <th>백다다기_가격(원/kg)</th>\n",
              "      <th>애호박_거래량(kg)</th>\n",
              "      <th>애호박_가격(원/kg)</th>\n",
              "      <th>캠벨얼리_거래량(kg)</th>\n",
              "      <th>캠벨얼리_가격(원/kg)</th>\n",
              "      <th>샤인마스캇_거래량(kg)</th>\n",
              "      <th>샤인마스캇_가격(원/kg)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-01-01</td>\n",
              "      <td>금요일</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-01-02</td>\n",
              "      <td>토요일</td>\n",
              "      <td>80860.0</td>\n",
              "      <td>329.0</td>\n",
              "      <td>80272.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>122787.5</td>\n",
              "      <td>1281.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>11000.0</td>\n",
              "      <td>15019.0</td>\n",
              "      <td>5475.0</td>\n",
              "      <td>92334.0</td>\n",
              "      <td>1704.0</td>\n",
              "      <td>6359.0</td>\n",
              "      <td>1331.0</td>\n",
              "      <td>40028.0</td>\n",
              "      <td>348.0</td>\n",
              "      <td>4374.9</td>\n",
              "      <td>13242.0</td>\n",
              "      <td>16550.5</td>\n",
              "      <td>2339.0</td>\n",
              "      <td>10528.0</td>\n",
              "      <td>1729.0</td>\n",
              "      <td>13885.0</td>\n",
              "      <td>804.0</td>\n",
              "      <td>3853.0</td>\n",
              "      <td>3703.0</td>\n",
              "      <td>15797.0</td>\n",
              "      <td>2576.0</td>\n",
              "      <td>14634.0</td>\n",
              "      <td>1474.0</td>\n",
              "      <td>30950.0</td>\n",
              "      <td>1621.0</td>\n",
              "      <td>5125.0</td>\n",
              "      <td>9235.0</td>\n",
              "      <td>434.0</td>\n",
              "      <td>2109.0</td>\n",
              "      <td>19159.0</td>\n",
              "      <td>2414.0</td>\n",
              "      <td>880.0</td>\n",
              "      <td>2014.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-01-03</td>\n",
              "      <td>일요일</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016-01-04</td>\n",
              "      <td>월요일</td>\n",
              "      <td>1422742.5</td>\n",
              "      <td>478.0</td>\n",
              "      <td>1699653.7</td>\n",
              "      <td>382.0</td>\n",
              "      <td>2315079.0</td>\n",
              "      <td>1235.0</td>\n",
              "      <td>699.0</td>\n",
              "      <td>4464.0</td>\n",
              "      <td>141638.0</td>\n",
              "      <td>5210.0</td>\n",
              "      <td>994328.1</td>\n",
              "      <td>1716.0</td>\n",
              "      <td>262615.5</td>\n",
              "      <td>1212.0</td>\n",
              "      <td>1074699.1</td>\n",
              "      <td>345.0</td>\n",
              "      <td>122613.5</td>\n",
              "      <td>9923.0</td>\n",
              "      <td>427435.1</td>\n",
              "      <td>2153.0</td>\n",
              "      <td>82113.5</td>\n",
              "      <td>3960.0</td>\n",
              "      <td>558950.2</td>\n",
              "      <td>794.0</td>\n",
              "      <td>104930.3</td>\n",
              "      <td>4871.0</td>\n",
              "      <td>277326.5</td>\n",
              "      <td>2440.0</td>\n",
              "      <td>159800.0</td>\n",
              "      <td>1750.0</td>\n",
              "      <td>291057.0</td>\n",
              "      <td>1834.0</td>\n",
              "      <td>38525.5</td>\n",
              "      <td>7631.0</td>\n",
              "      <td>500702.0</td>\n",
              "      <td>2046.0</td>\n",
              "      <td>620539.0</td>\n",
              "      <td>2018.0</td>\n",
              "      <td>2703.8</td>\n",
              "      <td>3885.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-01-05</td>\n",
              "      <td>화요일</td>\n",
              "      <td>1167241.0</td>\n",
              "      <td>442.0</td>\n",
              "      <td>1423482.3</td>\n",
              "      <td>422.0</td>\n",
              "      <td>2092960.1</td>\n",
              "      <td>1213.0</td>\n",
              "      <td>1112.6</td>\n",
              "      <td>4342.0</td>\n",
              "      <td>126207.8</td>\n",
              "      <td>5387.0</td>\n",
              "      <td>787716.0</td>\n",
              "      <td>1715.0</td>\n",
              "      <td>221850.5</td>\n",
              "      <td>1197.0</td>\n",
              "      <td>825681.9</td>\n",
              "      <td>350.0</td>\n",
              "      <td>79055.9</td>\n",
              "      <td>9529.0</td>\n",
              "      <td>334636.8</td>\n",
              "      <td>2220.0</td>\n",
              "      <td>80144.0</td>\n",
              "      <td>3333.0</td>\n",
              "      <td>444353.7</td>\n",
              "      <td>763.0</td>\n",
              "      <td>100699.5</td>\n",
              "      <td>5129.0</td>\n",
              "      <td>218465.2</td>\n",
              "      <td>2437.0</td>\n",
              "      <td>153084.0</td>\n",
              "      <td>1822.0</td>\n",
              "      <td>194626.5</td>\n",
              "      <td>1833.0</td>\n",
              "      <td>32615.0</td>\n",
              "      <td>6926.0</td>\n",
              "      <td>147638.0</td>\n",
              "      <td>2268.0</td>\n",
              "      <td>231958.0</td>\n",
              "      <td>2178.0</td>\n",
              "      <td>8810.0</td>\n",
              "      <td>2853.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date   요일  배추_거래량(kg)  ...  캠벨얼리_가격(원/kg)  샤인마스캇_거래량(kg)  샤인마스캇_가격(원/kg)\n",
              "0  2016-01-01  금요일         0.0  ...            0.0            0.0             0.0\n",
              "1  2016-01-02  토요일     80860.0  ...         2014.0            0.0             0.0\n",
              "2  2016-01-03  일요일         0.0  ...            0.0            0.0             0.0\n",
              "3  2016-01-04  월요일   1422742.5  ...         3885.0            0.0             0.0\n",
              "4  2016-01-05  화요일   1167241.0  ...         2853.0            0.0             0.0\n",
              "\n",
              "[5 rows x 44 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bm_3kM0uvW7n"
      },
      "source": [
        "## 데이터 정규화\n",
        "\n",
        "요일을 0 ~ 6으로 변환 후 각 컬럼 최대값으로 나눠 0 ~ 1값으로 정규화 진행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26pQKBb4vW7o"
      },
      "source": [
        "week_day_map = {}\n",
        "for i, d in enumerate(data['요일'].unique()):\n",
        "    week_day_map[d] = i\n",
        "data['요일'] = data['요일'].map(week_day_map)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwtL-SjKvW7o"
      },
      "source": [
        "norm = data.iloc[:, 1:].max(0)\n",
        "data.iloc[:, 1:] = data.iloc[:, 1:] / norm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwNrrVimvW7p"
      },
      "source": [
        "## 하이퍼파라미터"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "TOtFfBPUvW7p"
      },
      "source": [
        "device = torch.device(\"cuda:0\") # GPU 사용\n",
        "target_n = 21 # 맞춰야하는 품목/품종의 수\n",
        "learning_rate = 5e-4 # 학습률\n",
        "BATCH_SIZE = 128 # 배치사이즈\n",
        "EPOCHS = 50 # 총 eopochs\n",
        "teacher_forcing = False # 교사강요 설정\n",
        "n_layers = 3 # rnn레이어 층\n",
        "dropout = 0.2 # 드롭아웃\n",
        "window_size = 28 # 인코더 시퀀스 길이\n",
        "future_size = 28 # 디코더 시퀀스 길이\n",
        "hidden_dim = 128 # rnn 히든차원\n",
        "save_path = f'/content/drive/MyDrive/Colab Notebooks/ model/best_model.pt' # 모델 저장 경로"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGUK32GfvW7p"
      },
      "source": [
        "## 전처리\n",
        "시계열 학습이 가능한 형태로 전처리\n",
        "\n",
        "과거 28일의 변화를 보고 미래 28일을 예측"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "U0DDpPKuGqzo",
        "outputId": "6f53298e-4d2c-4880-e098-0c0d423a29be"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>요일</th>\n",
              "      <th>배추_거래량(kg)</th>\n",
              "      <th>배추_가격(원/kg)</th>\n",
              "      <th>무_거래량(kg)</th>\n",
              "      <th>무_가격(원/kg)</th>\n",
              "      <th>양파_거래량(kg)</th>\n",
              "      <th>양파_가격(원/kg)</th>\n",
              "      <th>건고추_거래량(kg)</th>\n",
              "      <th>건고추_가격(원/kg)</th>\n",
              "      <th>마늘_거래량(kg)</th>\n",
              "      <th>마늘_가격(원/kg)</th>\n",
              "      <th>대파_거래량(kg)</th>\n",
              "      <th>대파_가격(원/kg)</th>\n",
              "      <th>얼갈이배추_거래량(kg)</th>\n",
              "      <th>얼갈이배추_가격(원/kg)</th>\n",
              "      <th>양배추_거래량(kg)</th>\n",
              "      <th>양배추_가격(원/kg)</th>\n",
              "      <th>깻잎_거래량(kg)</th>\n",
              "      <th>깻잎_가격(원/kg)</th>\n",
              "      <th>시금치_거래량(kg)</th>\n",
              "      <th>시금치_가격(원/kg)</th>\n",
              "      <th>미나리_거래량(kg)</th>\n",
              "      <th>미나리_가격(원/kg)</th>\n",
              "      <th>당근_거래량(kg)</th>\n",
              "      <th>당근_가격(원/kg)</th>\n",
              "      <th>파프리카_거래량(kg)</th>\n",
              "      <th>파프리카_가격(원/kg)</th>\n",
              "      <th>새송이_거래량(kg)</th>\n",
              "      <th>새송이_가격(원/kg)</th>\n",
              "      <th>팽이버섯_거래량(kg)</th>\n",
              "      <th>팽이버섯_가격(원/kg)</th>\n",
              "      <th>토마토_거래량(kg)</th>\n",
              "      <th>토마토_가격(원/kg)</th>\n",
              "      <th>청상추_거래량(kg)</th>\n",
              "      <th>청상추_가격(원/kg)</th>\n",
              "      <th>백다다기_거래량(kg)</th>\n",
              "      <th>백다다기_가격(원/kg)</th>\n",
              "      <th>애호박_거래량(kg)</th>\n",
              "      <th>애호박_가격(원/kg)</th>\n",
              "      <th>캠벨얼리_거래량(kg)</th>\n",
              "      <th>캠벨얼리_가격(원/kg)</th>\n",
              "      <th>샤인마스캇_거래량(kg)</th>\n",
              "      <th>샤인마스캇_가격(원/kg)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-01-01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-01-02</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.015520</td>\n",
              "      <td>0.0658</td>\n",
              "      <td>0.020797</td>\n",
              "      <td>0.264706</td>\n",
              "      <td>0.024437</td>\n",
              "      <td>0.6405</td>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.064389</td>\n",
              "      <td>0.013751</td>\n",
              "      <td>0.853468</td>\n",
              "      <td>0.070877</td>\n",
              "      <td>0.535512</td>\n",
              "      <td>0.010287</td>\n",
              "      <td>0.442634</td>\n",
              "      <td>0.034353</td>\n",
              "      <td>0.216283</td>\n",
              "      <td>0.017059</td>\n",
              "      <td>0.924333</td>\n",
              "      <td>0.024831</td>\n",
              "      <td>0.166905</td>\n",
              "      <td>0.056230</td>\n",
              "      <td>0.206571</td>\n",
              "      <td>0.018154</td>\n",
              "      <td>0.214400</td>\n",
              "      <td>0.012547</td>\n",
              "      <td>0.283559</td>\n",
              "      <td>0.050133</td>\n",
              "      <td>0.64400</td>\n",
              "      <td>0.086461</td>\n",
              "      <td>0.373070</td>\n",
              "      <td>0.024183</td>\n",
              "      <td>0.220604</td>\n",
              "      <td>0.060900</td>\n",
              "      <td>0.511068</td>\n",
              "      <td>0.000197</td>\n",
              "      <td>0.398376</td>\n",
              "      <td>0.023032</td>\n",
              "      <td>0.356152</td>\n",
              "      <td>0.000590</td>\n",
              "      <td>0.08056</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-01-03</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016-01-04</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.273068</td>\n",
              "      <td>0.0956</td>\n",
              "      <td>0.440354</td>\n",
              "      <td>0.280882</td>\n",
              "      <td>0.460735</td>\n",
              "      <td>0.6175</td>\n",
              "      <td>0.001690</td>\n",
              "      <td>0.026130</td>\n",
              "      <td>0.129684</td>\n",
              "      <td>0.812159</td>\n",
              "      <td>0.763265</td>\n",
              "      <td>0.539283</td>\n",
              "      <td>0.424853</td>\n",
              "      <td>0.403060</td>\n",
              "      <td>0.922336</td>\n",
              "      <td>0.214419</td>\n",
              "      <td>0.478118</td>\n",
              "      <td>0.692657</td>\n",
              "      <td>0.641277</td>\n",
              "      <td>0.153632</td>\n",
              "      <td>0.438569</td>\n",
              "      <td>0.473118</td>\n",
              "      <td>0.730787</td>\n",
              "      <td>0.211733</td>\n",
              "      <td>0.341704</td>\n",
              "      <td>0.372999</td>\n",
              "      <td>0.880117</td>\n",
              "      <td>0.61000</td>\n",
              "      <td>0.944132</td>\n",
              "      <td>0.442926</td>\n",
              "      <td>0.227416</td>\n",
              "      <td>0.249592</td>\n",
              "      <td>0.457792</td>\n",
              "      <td>0.422302</td>\n",
              "      <td>0.227365</td>\n",
              "      <td>0.386475</td>\n",
              "      <td>0.745976</td>\n",
              "      <td>0.297728</td>\n",
              "      <td>0.001814</td>\n",
              "      <td>0.15540</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-01-05</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.224029</td>\n",
              "      <td>0.0884</td>\n",
              "      <td>0.368802</td>\n",
              "      <td>0.310294</td>\n",
              "      <td>0.416530</td>\n",
              "      <td>0.6065</td>\n",
              "      <td>0.002690</td>\n",
              "      <td>0.025416</td>\n",
              "      <td>0.115556</td>\n",
              "      <td>0.839751</td>\n",
              "      <td>0.604666</td>\n",
              "      <td>0.538969</td>\n",
              "      <td>0.358904</td>\n",
              "      <td>0.398071</td>\n",
              "      <td>0.708623</td>\n",
              "      <td>0.217526</td>\n",
              "      <td>0.308270</td>\n",
              "      <td>0.665154</td>\n",
              "      <td>0.502053</td>\n",
              "      <td>0.158413</td>\n",
              "      <td>0.428050</td>\n",
              "      <td>0.398208</td>\n",
              "      <td>0.580960</td>\n",
              "      <td>0.203467</td>\n",
              "      <td>0.327927</td>\n",
              "      <td>0.392756</td>\n",
              "      <td>0.693316</td>\n",
              "      <td>0.60925</td>\n",
              "      <td>0.904452</td>\n",
              "      <td>0.461149</td>\n",
              "      <td>0.152071</td>\n",
              "      <td>0.249456</td>\n",
              "      <td>0.387559</td>\n",
              "      <td>0.383287</td>\n",
              "      <td>0.067041</td>\n",
              "      <td>0.428410</td>\n",
              "      <td>0.278846</td>\n",
              "      <td>0.321334</td>\n",
              "      <td>0.005911</td>\n",
              "      <td>0.11412</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1728</th>\n",
              "      <td>2020-09-24</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.356409</td>\n",
              "      <td>0.3678</td>\n",
              "      <td>0.532584</td>\n",
              "      <td>0.727941</td>\n",
              "      <td>0.454038</td>\n",
              "      <td>0.4950</td>\n",
              "      <td>0.006813</td>\n",
              "      <td>0.111809</td>\n",
              "      <td>0.123020</td>\n",
              "      <td>0.744349</td>\n",
              "      <td>0.591275</td>\n",
              "      <td>0.747957</td>\n",
              "      <td>0.713114</td>\n",
              "      <td>0.621217</td>\n",
              "      <td>0.563427</td>\n",
              "      <td>0.710379</td>\n",
              "      <td>0.310033</td>\n",
              "      <td>0.699986</td>\n",
              "      <td>0.104786</td>\n",
              "      <td>0.451620</td>\n",
              "      <td>0.320572</td>\n",
              "      <td>0.591398</td>\n",
              "      <td>0.553347</td>\n",
              "      <td>0.417333</td>\n",
              "      <td>0.306607</td>\n",
              "      <td>0.704954</td>\n",
              "      <td>0.637287</td>\n",
              "      <td>0.73175</td>\n",
              "      <td>0.768054</td>\n",
              "      <td>0.644141</td>\n",
              "      <td>0.111332</td>\n",
              "      <td>0.760343</td>\n",
              "      <td>0.602816</td>\n",
              "      <td>0.249530</td>\n",
              "      <td>0.128151</td>\n",
              "      <td>0.566868</td>\n",
              "      <td>0.376438</td>\n",
              "      <td>0.505459</td>\n",
              "      <td>0.338341</td>\n",
              "      <td>0.14480</td>\n",
              "      <td>0.740842</td>\n",
              "      <td>0.273500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1729</th>\n",
              "      <td>2020-09-25</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.360848</td>\n",
              "      <td>0.3578</td>\n",
              "      <td>0.486887</td>\n",
              "      <td>0.743382</td>\n",
              "      <td>0.412859</td>\n",
              "      <td>0.4775</td>\n",
              "      <td>0.004562</td>\n",
              "      <td>0.135188</td>\n",
              "      <td>0.116213</td>\n",
              "      <td>0.785503</td>\n",
              "      <td>0.599806</td>\n",
              "      <td>0.703646</td>\n",
              "      <td>0.685951</td>\n",
              "      <td>0.680745</td>\n",
              "      <td>0.615180</td>\n",
              "      <td>0.677439</td>\n",
              "      <td>0.330832</td>\n",
              "      <td>0.762320</td>\n",
              "      <td>0.133999</td>\n",
              "      <td>0.446839</td>\n",
              "      <td>0.665987</td>\n",
              "      <td>0.310036</td>\n",
              "      <td>0.523660</td>\n",
              "      <td>0.472800</td>\n",
              "      <td>0.283729</td>\n",
              "      <td>0.695612</td>\n",
              "      <td>0.707492</td>\n",
              "      <td>0.74850</td>\n",
              "      <td>0.770308</td>\n",
              "      <td>0.657555</td>\n",
              "      <td>0.119214</td>\n",
              "      <td>0.761568</td>\n",
              "      <td>0.645499</td>\n",
              "      <td>0.231212</td>\n",
              "      <td>0.141775</td>\n",
              "      <td>0.566490</td>\n",
              "      <td>0.436066</td>\n",
              "      <td>0.495279</td>\n",
              "      <td>0.321862</td>\n",
              "      <td>0.14472</td>\n",
              "      <td>0.794687</td>\n",
              "      <td>0.271100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1730</th>\n",
              "      <td>2020-09-26</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.318814</td>\n",
              "      <td>0.3520</td>\n",
              "      <td>0.442875</td>\n",
              "      <td>0.790441</td>\n",
              "      <td>0.415758</td>\n",
              "      <td>0.4805</td>\n",
              "      <td>0.002318</td>\n",
              "      <td>0.131764</td>\n",
              "      <td>0.101044</td>\n",
              "      <td>0.867498</td>\n",
              "      <td>0.622395</td>\n",
              "      <td>0.668133</td>\n",
              "      <td>0.670464</td>\n",
              "      <td>0.696708</td>\n",
              "      <td>0.431408</td>\n",
              "      <td>0.824114</td>\n",
              "      <td>0.387790</td>\n",
              "      <td>0.740402</td>\n",
              "      <td>0.186425</td>\n",
              "      <td>0.508277</td>\n",
              "      <td>0.405116</td>\n",
              "      <td>0.514934</td>\n",
              "      <td>0.244589</td>\n",
              "      <td>0.374667</td>\n",
              "      <td>0.334350</td>\n",
              "      <td>0.704342</td>\n",
              "      <td>0.790250</td>\n",
              "      <td>0.73550</td>\n",
              "      <td>0.768347</td>\n",
              "      <td>0.662364</td>\n",
              "      <td>0.138147</td>\n",
              "      <td>0.716113</td>\n",
              "      <td>0.727384</td>\n",
              "      <td>0.208633</td>\n",
              "      <td>0.148668</td>\n",
              "      <td>0.578957</td>\n",
              "      <td>0.469269</td>\n",
              "      <td>0.456182</td>\n",
              "      <td>0.349917</td>\n",
              "      <td>0.14764</td>\n",
              "      <td>0.819581</td>\n",
              "      <td>0.265900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1731</th>\n",
              "      <td>2020-09-27</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.004874</td>\n",
              "      <td>0.6132</td>\n",
              "      <td>0.009903</td>\n",
              "      <td>0.837500</td>\n",
              "      <td>0.003630</td>\n",
              "      <td>0.5280</td>\n",
              "      <td>0.000145</td>\n",
              "      <td>0.130728</td>\n",
              "      <td>0.000568</td>\n",
              "      <td>0.814809</td>\n",
              "      <td>0.014041</td>\n",
              "      <td>0.586424</td>\n",
              "      <td>0.006507</td>\n",
              "      <td>0.265381</td>\n",
              "      <td>0.014223</td>\n",
              "      <td>0.620261</td>\n",
              "      <td>0.008422</td>\n",
              "      <td>0.851249</td>\n",
              "      <td>0.001637</td>\n",
              "      <td>0.512202</td>\n",
              "      <td>0.003611</td>\n",
              "      <td>0.223297</td>\n",
              "      <td>0.000078</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.015125</td>\n",
              "      <td>0.73650</td>\n",
              "      <td>0.014771</td>\n",
              "      <td>0.651228</td>\n",
              "      <td>0.000711</td>\n",
              "      <td>0.514562</td>\n",
              "      <td>0.001711</td>\n",
              "      <td>0.225567</td>\n",
              "      <td>0.000129</td>\n",
              "      <td>0.700227</td>\n",
              "      <td>0.002962</td>\n",
              "      <td>0.479788</td>\n",
              "      <td>0.014572</td>\n",
              "      <td>0.14268</td>\n",
              "      <td>0.025464</td>\n",
              "      <td>0.267475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1732</th>\n",
              "      <td>2020-09-28</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.461603</td>\n",
              "      <td>0.3734</td>\n",
              "      <td>0.711839</td>\n",
              "      <td>0.843382</td>\n",
              "      <td>0.444954</td>\n",
              "      <td>0.4820</td>\n",
              "      <td>0.003942</td>\n",
              "      <td>0.128907</td>\n",
              "      <td>0.160765</td>\n",
              "      <td>0.741543</td>\n",
              "      <td>0.746435</td>\n",
              "      <td>0.821496</td>\n",
              "      <td>0.861241</td>\n",
              "      <td>0.781177</td>\n",
              "      <td>0.628227</td>\n",
              "      <td>0.884400</td>\n",
              "      <td>0.611345</td>\n",
              "      <td>0.779282</td>\n",
              "      <td>0.439825</td>\n",
              "      <td>0.581205</td>\n",
              "      <td>0.513605</td>\n",
              "      <td>0.859737</td>\n",
              "      <td>0.551751</td>\n",
              "      <td>0.533600</td>\n",
              "      <td>0.599141</td>\n",
              "      <td>0.719274</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.84000</td>\n",
              "      <td>0.981008</td>\n",
              "      <td>0.776765</td>\n",
              "      <td>0.222775</td>\n",
              "      <td>0.683723</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.230603</td>\n",
              "      <td>0.251959</td>\n",
              "      <td>0.542690</td>\n",
              "      <td>0.802724</td>\n",
              "      <td>0.410446</td>\n",
              "      <td>0.403829</td>\n",
              "      <td>0.15044</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.274950</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1733 rows × 44 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            date        요일  ...  샤인마스캇_거래량(kg)  샤인마스캇_가격(원/kg)\n",
              "0     2016-01-01  0.000000  ...       0.000000        0.000000\n",
              "1     2016-01-02  0.166667  ...       0.000000        0.000000\n",
              "2     2016-01-03  0.333333  ...       0.000000        0.000000\n",
              "3     2016-01-04  0.500000  ...       0.000000        0.000000\n",
              "4     2016-01-05  0.666667  ...       0.000000        0.000000\n",
              "...          ...       ...  ...            ...             ...\n",
              "1728  2020-09-24  1.000000  ...       0.740842        0.273500\n",
              "1729  2020-09-25  0.000000  ...       0.794687        0.271100\n",
              "1730  2020-09-26  0.166667  ...       0.819581        0.265900\n",
              "1731  2020-09-27  0.333333  ...       0.025464        0.267475\n",
              "1732  2020-09-28  0.500000  ...       1.000000        0.274950\n",
              "\n",
              "[1733 rows x 44 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxzMkgETvW7q"
      },
      "source": [
        "x_data = []\n",
        "y_data = []\n",
        "for i in range(data.shape[0]-window_size-future_size):\n",
        "    x = data.iloc[i:i+window_size, 1:].to_numpy()\n",
        "    y = data.iloc[i+window_size:i+window_size+future_size, 3::2].to_numpy()\n",
        "    y_0 = np.zeros([1, y.shape[1]]) # 디코더 첫 입력값 추가\n",
        "    x_data.append(x)\n",
        "    y_data.append(np.concatenate([y_0, y], axis=0))\n",
        "x_data = np.array(x_data)\n",
        "y_data = np.array(y_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "9d-36neSMr-U",
        "outputId": "f648c6b4-530f-419f-b893-25ec9b72dc1a"
      },
      "source": [
        "x_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5609f17f5e28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'x_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qL_9d4paSHNc"
      },
      "source": [
        "y_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvSvbE4cvW7q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d021b8f5-9cc3-4f41-f3a1-21569c12e28c"
      },
      "source": [
        "x_data.shape, y_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1677, 28, 43), (1677, 29, 21))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGZdvW1cvW7q"
      },
      "source": [
        "train_test_split = 1\n",
        "x_train = x_data[:-train_test_split-future_size]\n",
        "y_train = y_data[:-train_test_split-future_size]\n",
        "x_val = x_data[-train_test_split:]\n",
        "y_val = y_data[-train_test_split:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7mArwetvW7r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05590d68-ed27-4ae5-d000-0c633be91a5f"
      },
      "source": [
        "x_train.shape, y_train.shape, x_val.shape, y_val.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1648, 28, 43), (1648, 29, 21), (1, 28, 43), (1, 29, 21))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUbKJ8hfvW7r"
      },
      "source": [
        "## 데이터셋 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvtFYaltvW7r"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, encoder_input, decoder_input):\n",
        "        self.encoder_input = encoder_input\n",
        "        self.decoder_input = decoder_input\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.encoder_input)\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        return {\n",
        "            'encoder_input' : torch.tensor(self.encoder_input[i], dtype=torch.float32),\n",
        "            'decoder_input' : torch.tensor(self.decoder_input[i], dtype=torch.float32)\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOJwY_QcvW7r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48c84b61-ce83-42c1-901b-84590dbb5822"
      },
      "source": [
        "train_dataset = CustomDataset(x_train, y_train)\n",
        "val_dataset = CustomDataset(x_val, y_val)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=16, shuffle=True)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, num_workers=16, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnZsqhJcvW7s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd6552b7-7fef-4a4f-e753-af9230cff89f"
      },
      "source": [
        "sample_batch = next(iter(train_dataloader))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dJ1yoZuvW7s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d2c167d-fc8b-4d36-efd6-bb0e882063a9"
      },
      "source": [
        "sample_batch['encoder_input'].shape, sample_batch['decoder_input'].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([128, 28, 43]), torch.Size([128, 29, 21]))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QV7PCRIAvW7s"
      },
      "source": [
        "## 모델\n",
        "\n",
        "어텐션이 적용된 seq2seq모델\n",
        "\n",
        "인코더와 디코더는 GRU 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "WfkioqaxvW7s"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.rnn = nn.GRU(input_dim, hidden_dim, n_layers, dropout=dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, inp_seq):\n",
        "        inp_seq = inp_seq.permute(1,0,2)\n",
        "        outputs, hidden = self.rnn(inp_seq)\n",
        "        \n",
        "        return outputs, hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "jqmQ3kwzvW7s"
      },
      "source": [
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, dec_output_dim, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W1 = nn.Linear(dec_output_dim, units)\n",
        "        self.W2 = nn.Linear(dec_output_dim, units)\n",
        "        self.V = nn.Linear(dec_output_dim, 1)\n",
        "\n",
        "    def forward(self, hidden, enc_output):\n",
        "        query_with_time_axis = hidden.unsqueeze(1)\n",
        "        \n",
        "        score = self.V(torch.tanh(self.W1(query_with_time_axis) + self.W2(enc_output)))\n",
        "        \n",
        "        attention_weights = torch.softmax(score, axis=1)\n",
        "        \n",
        "        context_vector = attention_weights * enc_output\n",
        "        context_vector = torch.sum(context_vector, dim=1)\n",
        "\n",
        "        return context_vector, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOv-IzaYvW7t"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, dec_feature_size, encoder_hidden_dim, output_dim, decoder_hidden_dim, n_layers, dropout, attention):\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.decoder_hidden_dim = decoder_hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        self.attention = attention\n",
        "        \n",
        "        self.layer = nn.Linear(dec_feature_size, encoder_hidden_dim)\n",
        "        self.rnn = nn.GRU(encoder_hidden_dim*2, decoder_hidden_dim, n_layers, dropout=dropout)\n",
        "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, enc_output, dec_input, hidden):\n",
        "        dec_input = self.layer(dec_input)\n",
        "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "        dec_input = torch.cat([torch.sum(context_vector, dim=0), dec_input], dim=1)\n",
        "        dec_input = dec_input.unsqueeze(0)\n",
        "        \n",
        "        output, hidden = self.rnn(dec_input, hidden)\n",
        "\n",
        "        prediction = self.fc_out(output.sum(0))\n",
        "        \n",
        "        return prediction, hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjKPlQmevW7t"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, attention):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        \n",
        "    def forward(self, encoder_input, decoder_input, teacher_forcing=False):\n",
        "        batch_size = decoder_input.size(0)\n",
        "        trg_len = decoder_input.size(1)\n",
        "        \n",
        "        outputs = torch.zeros(batch_size, trg_len-1, self.decoder.output_dim).to(device)\n",
        "        enc_output, hidden = self.encoder(encoder_input)\n",
        "        \n",
        "        dec_input = decoder_input[:, 0]\n",
        "        for t in range(1, trg_len):\n",
        "            output, hidden = self.decoder(enc_output, dec_input, hidden)\n",
        "            outputs[:, t-1] = output\n",
        "            if teacher_forcing == True:\n",
        "                dec_input = decoder_input[:, t]\n",
        "            else:\n",
        "                dec_input = output\n",
        "        \n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iZ8tw4pvW7u"
      },
      "source": [
        "encoder = Encoder(input_dim=x_data.shape[-1], hidden_dim=hidden_dim, n_layers=n_layers, dropout=dropout)\n",
        "attention = BahdanauAttention(dec_output_dim=hidden_dim, units=hidden_dim)\n",
        "decoder = Decoder(\n",
        "    dec_feature_size=target_n, encoder_hidden_dim=hidden_dim, output_dim=target_n,\n",
        "    decoder_hidden_dim=hidden_dim, n_layers=n_layers, dropout=dropout,\n",
        "    attention = attention\n",
        ")\n",
        "\n",
        "model = Seq2Seq(encoder, decoder, attention)\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgQ5X064vW7u"
      },
      "source": [
        "## 평가 함수\n",
        "\n",
        "평가를 위한 NMAE 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "is9ajEKUvW7u"
      },
      "source": [
        "def my_custom_metric(pred, true):\n",
        "    pred = pred[:, [6, 13, 27]]\n",
        "    true = true[:, [6, 13, 27]]\n",
        "    target = torch.where(true!=0)\n",
        "    true = true[target]\n",
        "    pred = pred[target]\n",
        "    score = torch.mean(torch.abs((true-pred))/(true))\n",
        "    \n",
        "    return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGIeQKSZvW7u"
      },
      "source": [
        "## 옵티마이저 및 손실함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "sPQCMKVXvW7u"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.L1Loss() # mae\n",
        "custom_metric = my_custom_metric"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_F8-kTQHvW7v"
      },
      "source": [
        "## 학습 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVMaCuCwvW7v"
      },
      "source": [
        "def train_step(batch_item, epoch, batch, training, teacher_forcing):\n",
        "    encoder_input = batch_item['encoder_input'].to(device)\n",
        "    decoder_input = batch_item['decoder_input'].to(device)\n",
        "    if training is True:\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast():\n",
        "            output = model(encoder_input, decoder_input, teacher_forcing)\n",
        "            loss = criterion(output, decoder_input[:,1:])\n",
        "            score = custom_metric(output, decoder_input[:,1:])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        return loss, score\n",
        "    else:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            output = model(encoder_input, decoder_input, False)\n",
        "            loss = criterion(output, decoder_input[:,1:])\n",
        "            score = custom_metric(output, decoder_input[:,1:])\n",
        "        return loss, score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_f1dfoX7vW7v"
      },
      "source": [
        "## 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uaef4_nkFJL6",
        "outputId": "fc16e101-8e2a-4d3c-c7ec-4166b3acfc67"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-qOSV56vW7v",
        "outputId": "65d1b195-2cc7-4d47-ed29-4dbcfc5183d2"
      },
      "source": [
        "loss_plot, val_loss_plot = [], []\n",
        "score_plot, val_score_plot = [], []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss, total_val_loss = 0, 0\n",
        "    total_score, total_val_score = 0, 0\n",
        "    \n",
        "    tqdm_dataset = tqdm(enumerate(train_dataloader))\n",
        "    training = True\n",
        "    for batch, batch_item in tqdm_dataset:\n",
        "        batch_loss, batch_score = train_step(batch_item, epoch, batch, training, teacher_forcing)\n",
        "        total_loss += batch_loss\n",
        "        total_score += batch_score\n",
        "        \n",
        "        tqdm_dataset.set_postfix({\n",
        "            'Epoch': epoch + 1,\n",
        "            'Loss': '{:06f}'.format(batch_loss.item()),\n",
        "            'Total Loss' : '{:06f}'.format(total_loss/(batch+1)),\n",
        "            'Score': '{:06f}'.format(batch_score.item()),\n",
        "            'Total Score' : '{:06f}'.format(total_score/(batch+1)),\n",
        "        })\n",
        "    loss_plot.append(total_loss/(batch+1))\n",
        "    score_plot.append(total_score/(batch+1))\n",
        "    \n",
        "    tqdm_dataset = tqdm(enumerate(val_dataloader))\n",
        "    training = False\n",
        "    for batch, batch_item in tqdm_dataset:\n",
        "        batch_loss, batch_val_score = train_step(batch_item, epoch, batch, training, teacher_forcing)\n",
        "        total_val_loss += batch_loss\n",
        "        total_val_score += batch_val_score\n",
        "        \n",
        "        tqdm_dataset.set_postfix({\n",
        "            'Epoch': epoch + 1,\n",
        "            'Val Loss': '{:06f}'.format(batch_loss.item()),\n",
        "            'Total Val Loss' : '{:06f}'.format(total_val_loss/(batch+1)),\n",
        "            'Val Score': '{:06f}'.format(batch_val_score.item()),\n",
        "            'Total Val Score' : '{:06f}'.format(total_val_score/(batch+1)),\n",
        "        })\n",
        "    val_loss_plot.append(total_val_loss/(batch+1))\n",
        "    val_score_plot.append(total_val_score/(batch+1))\n",
        "    \n",
        "    if np.min(val_loss_plot) == val_loss_plot[-1]:\n",
        "        torch.save(model, save_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "13it [00:04,  2.79it/s, Epoch=1, Loss=0.143691, Total Loss=0.180263, Score=0.379739, Total Score=0.576583]\n",
            "1it [00:00,  3.87it/s, Epoch=1, Val Loss=0.246930, Total Val Loss=0.246930, Val Score=0.426005, Total Val Score=0.426005]\n",
            "13it [00:04,  2.98it/s, Epoch=2, Loss=0.123758, Total Loss=0.131610, Score=0.343928, Total Score=0.366073]\n",
            "1it [00:00,  3.80it/s, Epoch=2, Val Loss=0.233278, Total Val Loss=0.233278, Val Score=0.464174, Total Val Score=0.464174]\n",
            "13it [00:04,  3.00it/s, Epoch=3, Loss=0.116190, Total Loss=0.122500, Score=0.335143, Total Score=0.329902]\n",
            "1it [00:00,  3.58it/s, Epoch=3, Val Loss=0.198750, Total Val Loss=0.198750, Val Score=0.382493, Total Val Score=0.382493]\n",
            "13it [00:04,  3.01it/s, Epoch=4, Loss=0.116699, Total Loss=0.117913, Score=0.278565, Total Score=0.301408]\n",
            "1it [00:00,  3.82it/s, Epoch=4, Val Loss=0.185955, Total Val Loss=0.185955, Val Score=0.386728, Total Val Score=0.386728]\n",
            "13it [00:04,  3.09it/s, Epoch=5, Loss=0.113226, Total Loss=0.115194, Score=0.263954, Total Score=0.296089]\n",
            "1it [00:00,  3.83it/s, Epoch=5, Val Loss=0.190097, Total Val Loss=0.190097, Val Score=0.401792, Total Val Score=0.401792]\n",
            "13it [00:04,  3.12it/s, Epoch=6, Loss=0.114975, Total Loss=0.113385, Score=0.330119, Total Score=0.282034]\n",
            "1it [00:00,  3.73it/s, Epoch=6, Val Loss=0.183221, Total Val Loss=0.183221, Val Score=0.392126, Total Val Score=0.392126]\n",
            "13it [00:04,  3.10it/s, Epoch=7, Loss=0.108673, Total Loss=0.111352, Score=0.266698, Total Score=0.274901]\n",
            "1it [00:00,  3.33it/s, Epoch=7, Val Loss=0.184564, Total Val Loss=0.184564, Val Score=0.393031, Total Val Score=0.393031]\n",
            "13it [00:04,  3.10it/s, Epoch=8, Loss=0.106573, Total Loss=0.109143, Score=0.315511, Total Score=0.271258]\n",
            "1it [00:00,  3.55it/s, Epoch=8, Val Loss=0.170710, Total Val Loss=0.170710, Val Score=0.367967, Total Val Score=0.367967]\n",
            "13it [00:04,  3.07it/s, Epoch=9, Loss=0.113451, Total Loss=0.107031, Score=0.253758, Total Score=0.266568]\n",
            "1it [00:00,  3.61it/s, Epoch=9, Val Loss=0.166661, Total Val Loss=0.166661, Val Score=0.365643, Total Val Score=0.365643]\n",
            "13it [00:04,  3.11it/s, Epoch=10, Loss=0.103762, Total Loss=0.104545, Score=0.239043, Total Score=0.251258]\n",
            "1it [00:00,  3.71it/s, Epoch=10, Val Loss=0.168358, Total Val Loss=0.168358, Val Score=0.354689, Total Val Score=0.354689]\n",
            "13it [00:04,  3.19it/s, Epoch=11, Loss=0.102987, Total Loss=0.103042, Score=0.225135, Total Score=0.246884]\n",
            "1it [00:00,  3.43it/s, Epoch=11, Val Loss=0.170424, Total Val Loss=0.170424, Val Score=0.353024, Total Val Score=0.353024]\n",
            "13it [00:04,  3.17it/s, Epoch=12, Loss=0.102409, Total Loss=0.101898, Score=0.231494, Total Score=0.238556]\n",
            "1it [00:00,  3.59it/s, Epoch=12, Val Loss=0.159122, Total Val Loss=0.159122, Val Score=0.324928, Total Val Score=0.324928]\n",
            "13it [00:04,  3.16it/s, Epoch=13, Loss=0.098916, Total Loss=0.100463, Score=0.214618, Total Score=0.236433]\n",
            "1it [00:00,  3.43it/s, Epoch=13, Val Loss=0.164835, Total Val Loss=0.164835, Val Score=0.333006, Total Val Score=0.333006]\n",
            "13it [00:04,  3.16it/s, Epoch=14, Loss=0.097631, Total Loss=0.099816, Score=0.216484, Total Score=0.234138]\n",
            "1it [00:00,  3.52it/s, Epoch=14, Val Loss=0.153540, Total Val Loss=0.153540, Val Score=0.313474, Total Val Score=0.313474]\n",
            "13it [00:04,  3.07it/s, Epoch=15, Loss=0.099076, Total Loss=0.099277, Score=0.212877, Total Score=0.230044]\n",
            "1it [00:00,  3.27it/s, Epoch=15, Val Loss=0.151354, Total Val Loss=0.151354, Val Score=0.312639, Total Val Score=0.312639]\n",
            "13it [00:04,  3.16it/s, Epoch=16, Loss=0.098041, Total Loss=0.098917, Score=0.210904, Total Score=0.230474]\n",
            "1it [00:00,  3.52it/s, Epoch=16, Val Loss=0.160589, Total Val Loss=0.160589, Val Score=0.322190, Total Val Score=0.322190]\n",
            "13it [00:04,  3.17it/s, Epoch=17, Loss=0.097235, Total Loss=0.098133, Score=0.219156, Total Score=0.228467]\n",
            "1it [00:00,  3.43it/s, Epoch=17, Val Loss=0.154459, Total Val Loss=0.154459, Val Score=0.317409, Total Val Score=0.317409]\n",
            "13it [00:04,  3.15it/s, Epoch=18, Loss=0.095732, Total Loss=0.097793, Score=0.213109, Total Score=0.225773]\n",
            "1it [00:00,  3.09it/s, Epoch=18, Val Loss=0.155478, Total Val Loss=0.155478, Val Score=0.328655, Total Val Score=0.328655]\n",
            "13it [00:04,  3.11it/s, Epoch=19, Loss=0.095381, Total Loss=0.097020, Score=0.196916, Total Score=0.221826]\n",
            "1it [00:00,  3.17it/s, Epoch=19, Val Loss=0.153487, Total Val Loss=0.153487, Val Score=0.314580, Total Val Score=0.314580]\n",
            "13it [00:04,  3.19it/s, Epoch=20, Loss=0.098478, Total Loss=0.096546, Score=0.214256, Total Score=0.220220]\n",
            "1it [00:00,  3.28it/s, Epoch=20, Val Loss=0.150744, Total Val Loss=0.150744, Val Score=0.321562, Total Val Score=0.321562]\n",
            "13it [00:04,  3.20it/s, Epoch=21, Loss=0.093880, Total Loss=0.096332, Score=0.270695, Total Score=0.220867]\n",
            "1it [00:00,  3.26it/s, Epoch=21, Val Loss=0.149086, Total Val Loss=0.149086, Val Score=0.323818, Total Val Score=0.323818]\n",
            "13it [00:04,  3.20it/s, Epoch=22, Loss=0.096351, Total Loss=0.095546, Score=0.206346, Total Score=0.216671]\n",
            "1it [00:00,  3.11it/s, Epoch=22, Val Loss=0.148301, Total Val Loss=0.148301, Val Score=0.317798, Total Val Score=0.317798]\n",
            "13it [00:04,  3.20it/s, Epoch=23, Loss=0.091791, Total Loss=0.094932, Score=0.200658, Total Score=0.215544]\n",
            "1it [00:00,  3.24it/s, Epoch=23, Val Loss=0.148856, Total Val Loss=0.148856, Val Score=0.315601, Total Val Score=0.315601]\n",
            "13it [00:04,  3.17it/s, Epoch=24, Loss=0.095292, Total Loss=0.094232, Score=0.198439, Total Score=0.211280]\n",
            "1it [00:00,  3.33it/s, Epoch=24, Val Loss=0.144391, Total Val Loss=0.144391, Val Score=0.329789, Total Val Score=0.329789]\n",
            "13it [00:04,  3.19it/s, Epoch=25, Loss=0.095386, Total Loss=0.093610, Score=0.190321, Total Score=0.209749]\n",
            "1it [00:00,  3.15it/s, Epoch=25, Val Loss=0.148502, Total Val Loss=0.148502, Val Score=0.340298, Total Val Score=0.340298]\n",
            "13it [00:03,  3.30it/s, Epoch=26, Loss=0.092341, Total Loss=0.092829, Score=0.185065, Total Score=0.208580]\n",
            "1it [00:00,  3.16it/s, Epoch=26, Val Loss=0.149093, Total Val Loss=0.149093, Val Score=0.344756, Total Val Score=0.344756]\n",
            "13it [00:03,  3.34it/s, Epoch=27, Loss=0.091508, Total Loss=0.091942, Score=0.263555, Total Score=0.202733]\n",
            "1it [00:00,  3.14it/s, Epoch=27, Val Loss=0.148775, Total Val Loss=0.148775, Val Score=0.328641, Total Val Score=0.328641]\n",
            "13it [00:03,  3.37it/s, Epoch=28, Loss=0.090563, Total Loss=0.091424, Score=0.195367, Total Score=0.200910]\n",
            "1it [00:00,  3.10it/s, Epoch=28, Val Loss=0.147225, Total Val Loss=0.147225, Val Score=0.316584, Total Val Score=0.316584]\n",
            "13it [00:03,  3.33it/s, Epoch=29, Loss=0.092011, Total Loss=0.090883, Score=0.185838, Total Score=0.197171]\n",
            "1it [00:00,  3.11it/s, Epoch=29, Val Loss=0.140121, Total Val Loss=0.140121, Val Score=0.312972, Total Val Score=0.312972]\n",
            "13it [00:03,  3.36it/s, Epoch=30, Loss=0.086890, Total Loss=0.090144, Score=0.234821, Total Score=0.194568]\n",
            "1it [00:00,  3.02it/s, Epoch=30, Val Loss=0.147658, Total Val Loss=0.147658, Val Score=0.318323, Total Val Score=0.318323]\n",
            "13it [00:03,  3.40it/s, Epoch=31, Loss=0.091394, Total Loss=0.089534, Score=0.177027, Total Score=0.193050]\n",
            "1it [00:00,  2.99it/s, Epoch=31, Val Loss=0.141926, Total Val Loss=0.141926, Val Score=0.307950, Total Val Score=0.307950]\n",
            "13it [00:03,  3.38it/s, Epoch=32, Loss=0.092042, Total Loss=0.088979, Score=0.177042, Total Score=0.190120]\n",
            "1it [00:00,  3.08it/s, Epoch=32, Val Loss=0.137786, Total Val Loss=0.137786, Val Score=0.295783, Total Val Score=0.295783]\n",
            "13it [00:03,  3.36it/s, Epoch=33, Loss=0.085796, Total Loss=0.088585, Score=0.167817, Total Score=0.191437]\n",
            "1it [00:00,  2.95it/s, Epoch=33, Val Loss=0.141313, Total Val Loss=0.141313, Val Score=0.289750, Total Val Score=0.289750]\n",
            "13it [00:03,  3.37it/s, Epoch=34, Loss=0.088672, Total Loss=0.088198, Score=0.257069, Total Score=0.189593]\n",
            "1it [00:00,  3.07it/s, Epoch=34, Val Loss=0.143566, Total Val Loss=0.143566, Val Score=0.300998, Total Val Score=0.300998]\n",
            "13it [00:03,  3.37it/s, Epoch=35, Loss=0.089276, Total Loss=0.087360, Score=0.172823, Total Score=0.182080]\n",
            "1it [00:00,  2.79it/s, Epoch=35, Val Loss=0.149999, Total Val Loss=0.149999, Val Score=0.307424, Total Val Score=0.307424]\n",
            "13it [00:03,  3.37it/s, Epoch=36, Loss=0.086709, Total Loss=0.086757, Score=0.255129, Total Score=0.184571]\n",
            "1it [00:00,  2.86it/s, Epoch=36, Val Loss=0.142023, Total Val Loss=0.142023, Val Score=0.284715, Total Val Score=0.284715]\n",
            "13it [00:03,  3.39it/s, Epoch=37, Loss=0.084951, Total Loss=0.086213, Score=0.160257, Total Score=0.182066]\n",
            "1it [00:00,  2.92it/s, Epoch=37, Val Loss=0.145544, Total Val Loss=0.145544, Val Score=0.306619, Total Val Score=0.306619]\n",
            "13it [00:03,  3.36it/s, Epoch=38, Loss=0.083881, Total Loss=0.085725, Score=0.163636, Total Score=0.179277]\n",
            "1it [00:00,  2.92it/s, Epoch=38, Val Loss=0.152163, Total Val Loss=0.152163, Val Score=0.296038, Total Val Score=0.296038]\n",
            "13it [00:03,  3.33it/s, Epoch=39, Loss=0.088149, Total Loss=0.085404, Score=0.240021, Total Score=0.177952]\n",
            "1it [00:00,  2.68it/s, Epoch=39, Val Loss=0.152946, Total Val Loss=0.152946, Val Score=0.304317, Total Val Score=0.304317]\n",
            "13it [00:03,  3.36it/s, Epoch=40, Loss=0.084618, Total Loss=0.084797, Score=0.224731, Total Score=0.174545]\n",
            "1it [00:00,  2.67it/s, Epoch=40, Val Loss=0.148714, Total Val Loss=0.148714, Val Score=0.302128, Total Val Score=0.302128]\n",
            "13it [00:03,  3.38it/s, Epoch=41, Loss=0.084436, Total Loss=0.084438, Score=0.241633, Total Score=0.174667]\n",
            "1it [00:00,  2.71it/s, Epoch=41, Val Loss=0.151714, Total Val Loss=0.151714, Val Score=0.298828, Total Val Score=0.298828]\n",
            "13it [00:03,  3.38it/s, Epoch=42, Loss=0.081832, Total Loss=0.084063, Score=0.161180, Total Score=0.172613]\n",
            "1it [00:00,  2.63it/s, Epoch=42, Val Loss=0.153663, Total Val Loss=0.153663, Val Score=0.306263, Total Val Score=0.306263]\n",
            "13it [00:03,  3.37it/s, Epoch=43, Loss=0.085099, Total Loss=0.083589, Score=0.158258, Total Score=0.169214]\n",
            "1it [00:00,  2.63it/s, Epoch=43, Val Loss=0.149691, Total Val Loss=0.149691, Val Score=0.310734, Total Val Score=0.310734]\n",
            "13it [00:03,  3.49it/s, Epoch=44, Loss=0.082178, Total Loss=0.083117, Score=0.155162, Total Score=0.167564]\n",
            "1it [00:00,  2.56it/s, Epoch=44, Val Loss=0.160821, Total Val Loss=0.160821, Val Score=0.299037, Total Val Score=0.299037]\n",
            "13it [00:03,  3.47it/s, Epoch=45, Loss=0.082259, Total Loss=0.082802, Score=0.229050, Total Score=0.166944]\n",
            "1it [00:00,  2.63it/s, Epoch=45, Val Loss=0.158762, Total Val Loss=0.158762, Val Score=0.303268, Total Val Score=0.303268]\n",
            "13it [00:03,  3.46it/s, Epoch=46, Loss=0.082383, Total Loss=0.082395, Score=0.153770, Total Score=0.164969]\n",
            "1it [00:00,  2.52it/s, Epoch=46, Val Loss=0.170174, Total Val Loss=0.170174, Val Score=0.310225, Total Val Score=0.310225]\n",
            "13it [00:03,  3.49it/s, Epoch=47, Loss=0.083463, Total Loss=0.082044, Score=0.149138, Total Score=0.164280]\n",
            "1it [00:00,  2.72it/s, Epoch=47, Val Loss=0.159723, Total Val Loss=0.159723, Val Score=0.304512, Total Val Score=0.304512]\n",
            "13it [00:03,  3.50it/s, Epoch=48, Loss=0.080030, Total Loss=0.081584, Score=0.148023, Total Score=0.163260]\n",
            "1it [00:00,  2.47it/s, Epoch=48, Val Loss=0.164482, Total Val Loss=0.164482, Val Score=0.307028, Total Val Score=0.307028]\n",
            "13it [00:03,  3.40it/s, Epoch=49, Loss=0.081735, Total Loss=0.081424, Score=0.153672, Total Score=0.161649]\n",
            "1it [00:00,  2.64it/s, Epoch=49, Val Loss=0.160546, Total Val Loss=0.160546, Val Score=0.303156, Total Val Score=0.303156]\n",
            "13it [00:03,  3.42it/s, Epoch=50, Loss=0.079536, Total Loss=0.081000, Score=0.143016, Total Score=0.158936]\n",
            "1it [00:00,  2.60it/s, Epoch=50, Val Loss=0.160967, Total Val Loss=0.160967, Val Score=0.304680, Total Val Score=0.304680]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ig8m5uRcvW7w"
      },
      "source": [
        "## 학습 결과"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "x34VrZBUvW7w",
        "outputId": "b307f497-54fc-4fb7-d74d-932abf30e9c2"
      },
      "source": [
        "plt.plot(loss_plot, label='train_loss')\n",
        "plt.plot(val_loss_plot, label='val_loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss(mae)')\n",
        "plt.title('loss_plot')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(score_plot, label='train_score')\n",
        "plt.plot(val_score_plot, label='val_score')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('score(nmae)')\n",
        "plt.title('score_plot')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCXjxmIevW7w"
      },
      "source": [
        "## 베스트모델 복원"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SJpceVMvW7w"
      },
      "source": [
        "model = torch.load(save_path)\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npTeWRGBvW7w"
      },
      "source": [
        "## 추론 및 제출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCnRnollvW7w"
      },
      "source": [
        "def predict(encoder_input):\n",
        "    model.train()\n",
        "    encoder_input = encoder_input.to(device)\n",
        "    decoder_input = torch.zeros([1, future_size+1, target_n], dtype=torch.float32).to(device)\n",
        "    with torch.no_grad():\n",
        "        output = model(encoder_input, decoder_input, False)\n",
        "    return output.cpu()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TZ8NJjYvW7w"
      },
      "source": [
        "submission = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/Dacon_data/sample_submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BI6DYx-PvW7x"
      },
      "source": [
        "public_date_list = submission[submission['예측대상일자'].str.contains('2020')]['예측대상일자'].str.split('+').str[0].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPBam_gHvW7x"
      },
      "source": [
        "### 추론\n",
        "\n",
        "일자별 추론을 진행합니다.\n",
        "\n",
        "data leakage가 발생하지 않도록 주의합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XGU_n8avW7x"
      },
      "source": [
        "outputs = []\n",
        "troch_norm = torch.tensor(norm.to_numpy()[2::2])\n",
        "for date in public_date_list:\n",
        "    test_df = pd.read_csv(f'/content/drive/MyDrive/Colab Notebooks/Data/Dacon_data/public_data/test_files/test_{date}.csv')\n",
        "    data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/Dacon_data/public_data/train.csv')\n",
        "    data = pd.concat([data, test_df]).iloc[-window_size:]\n",
        "    \n",
        "    week_day_map = {}\n",
        "    for i, d in enumerate(data['요일'].unique()):\n",
        "        week_day_map[d] = i\n",
        "    data['요일'] = data['요일'].map(week_day_map)\n",
        "    data = data.iloc[:,1:]/norm\n",
        "    \n",
        "    encoder_input = torch.tensor(data.to_numpy(), dtype=torch.float32)\n",
        "    encoder_input = encoder_input.unsqueeze(0)\n",
        "    output = predict(encoder_input)*troch_norm\n",
        "    \n",
        "    idx = submission[submission['예측대상일자'].str.contains(date)].index\n",
        "    submission.loc[idx, '배추_가격(원/kg)':] = output[0,[6,13,27]].numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmdgCcHXvW7x"
      },
      "source": [
        "submission.to_csv('/content/drive/MyDrive/Colab Notebooks/Data/Dacon_data/dacon_baseline.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTdVmnZzvW7x"
      },
      "source": [
        "제출 API 사용법 => https://dacon.io/forum/403557"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUU7wndZHczp",
        "outputId": "fdbd2d36-ba4f-4a22-eeac-2710ef9a8ee9"
      },
      "source": [
        "# !pip install dacon_submit_api-0.0.4-py3-none-any.whl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./dacon_submit_api-0.0.4-py3-none-any.whl\n",
            "Installing collected packages: dacon-submit-api\n",
            "Successfully installed dacon-submit-api-0.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7tIcMhrvW7x",
        "outputId": "66ae0414-cda0-4cea-e256-8436f4785a26"
      },
      "source": [
        "# from dacon_submit_api import dacon_submit_api \n",
        "\n",
        "# result = dacon_submit_api.post_submission_file(\n",
        "#     '/content/drive/MyDrive/Colab Notebooks/Data/Dacon_data/dacon_baseline.csv', \n",
        "#     '90f0735322c13e8725dffa8b314e1d4a41c50ae6af466fa2e2bd5079b9253803', \n",
        "#     '235801', \n",
        "#     'DACONIO', \n",
        "#     'DACON_Baseline'\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'isSubmitted': True, 'detail': 'Success'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVidCrbnvW7y"
      },
      "source": [
        "## Public LB Score : 0.3225"
      ]
    }
  ]
}